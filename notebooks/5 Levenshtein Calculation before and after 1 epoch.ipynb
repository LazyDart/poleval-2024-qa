{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../scripts\")\n",
    "\n",
    "from data_processing import poquad, processing\n",
    "from t5 import load_t5\n",
    "\n",
    "from Levenshtein import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = poquad.load_poquad_manually_downloaded(\"../data/poquad-manually-processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = poquad.dataset_into_str_input(train_df)\n",
    "valid_input = poquad.dataset_into_str_input(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_og, model_og = load_t5.load_plt5(\"../models/plt5-original-small\")\n",
    "tokenizer, model = load_t5.load_plt5(\"../models/plt5-small-2epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = valid_input.sample(100)\n",
    "\n",
    "distances = []\n",
    "\n",
    "for i in range(100):\n",
    "    output_og = tokenizer_og(sample[\"input_text\"].iloc[i], return_tensors=\"pt\").input_ids\n",
    "    output = tokenizer(sample[\"input_text\"].iloc[i], return_tensors=\"pt\").input_ids\n",
    "\n",
    "    gen_og = model_og.generate(output_og, max_length=128, num_beams=4, num_return_sequences=1, no_repeat_ngram_size=2, early_stopping=True)\n",
    "    gen = model.generate(output, max_length=128, num_beams=4, num_return_sequences=1, no_repeat_ngram_size=2, early_stopping=True)\n",
    "\n",
    "    gen_og_str = tokenizer_og.batch_decode(gen_og, skip_special_tokens=True)\n",
    "    gen_str = tokenizer.batch_decode(gen, skip_special_tokens=True)\n",
    "\n",
    "    dist_og = distance(sample[\"target_text\"].iloc[i], gen_og_str[0])\n",
    "    dist = distance(sample[\"target_text\"].iloc[i], gen_str[0])\n",
    "\n",
    "    distances.append((dist_og, dist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dist for dist in distances if dist[0] != dist[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kontekst: Wigilia Bożego Narodzenia  Zgodnie z tradycją w Polsce wieczerza wigilijna rozpoczyna się wraz z „pierwszą gwiazdką na niebie”. Jest to symboliczne nawiązanie do Gwiazdy Betlejemskiej zwiastującej narodziny Jezusa, którą według Biblii na wschodniej stronie nieba ujrzeli Trzej Królowie. Wieczerzę, jak każe obyczaj, postną, rozpoczyna się modlitwą i czytaniem fragmentu Ewangelii Mateusza, Łukasza lub Jana w części dotyczącej narodzin Jezusa. Potem uczestnicy wieczerzy wzajemnie przełamują się opłatkiem, jednocześnie składając sobie życzenia. Na stole przykrytym białym obrusem z wiązką sianka pod spodem ustawia się o jedno nakrycie więcej, niż wynosi liczba zgromadzonych osób. Dodatkowe miejsce przy stole wigilijnym przeznaczone jest dla niezapowiedzianego gościa, a zwyczaj ten upowszechnił się w XIX wieku. Ważnym zwyczajem towarzyszącym wigilii Bożego Narodzenia jest śpiewanie kolęd. Często też pod choinką umieszczane są prezenty, które wedle tradycji przynosić ma gwiazdor, św. Mikołaj, dzieciątko, aniołek lub gwiazdka.  pytanie: Od czego powinna zacząć się wieczerza?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"input_text\"].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['規ą̋腊ઠ藪...畑藪滬 [']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_og_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['規ą̋腊ઠ藪...畑藪滬 [']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad> 規ą̋腊ઠ藪...畑藪滬 [</s>']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_og.batch_decode(gen_og, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_input.sample(100)\n",
    "\n",
    "distances = []\n",
    "\n",
    "for i in range(100):\n",
    "    output_og = tokenizer_og(sample[\"input_text\"].iloc[i], return_tensors=\"pt\").input_ids\n",
    "    output = tokenizer(sample[\"input_text\"].iloc[i], return_tensors=\"pt\").input_ids\n",
    "\n",
    "    gen_og = model_og.generate(output_og, max_length=128, num_beams=4, num_return_sequences=1, no_repeat_ngram_size=2, early_stopping=True)\n",
    "    gen = model.generate(output, max_length=128, num_beams=4, num_return_sequences=1, no_repeat_ngram_size=2, early_stopping=True)\n",
    "\n",
    "    gen_og_str = tokenizer_og.batch_decode(gen_og, skip_special_tokens=True)\n",
    "    gen_str = tokenizer.batch_decode(gen, skip_special_tokens=True)\n",
    "\n",
    "    dist_og = distance(sample[\"target_text\"].iloc[i], gen_og_str[0])\n",
    "    dist = distance(sample[\"target_text\"].iloc[i], gen_str[0])\n",
    "\n",
    "    distances.append((dist_og, dist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dist for dist in distances if dist[0] != dist[1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mltorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
